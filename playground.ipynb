{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.0707, -0.0527, -1.5284],\n",
       "        [-0.3706,  0.6679, -0.1387],\n",
       "        [-0.1178,  0.5838,  0.1594],\n",
       "        [    inf,    -inf,    -inf],\n",
       "        [-0.5361,  0.7707,  1.2443]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.div(torch.randn((5,3)),torch.tensor([1,1,1,0,1]).view(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import pandas as pd\n",
    "import time\n",
    "import wandb\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "import FunctionCollection as fc\n",
    "import importlib\n",
    "fc = importlib.reload(fc)\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'C:\\Users\\jv97\\Desktop\\github\\Neutrino-Machine-Learning'\n",
    "\n",
    "run_name = 'oscNext_angle_m9'\n",
    "\n",
    "args = {'N_edge_feats': 6,\n",
    "        'N_dom_feats': 5,\n",
    "        'N_targets': 2,\n",
    "        'N_outputs': 4,\n",
    "        'N_metalayers': 1,\n",
    "        'N_hcs': 64,\n",
    "        'diagonal_cov': True,\n",
    "        'wandb_activated': True,\n",
    "        'type': 'twice_Polar_NLLH',\n",
    "        'zenith': True,\n",
    "        'id': wandb.util.generate_id()[:4],\n",
    "        'eps': 0,\n",
    "        'lr': 0.0209,\n",
    "        'filename': 'dev_level7_mu_e_tau_oscweight_000_unscaled.db',#dev_level7_mu_e_tau_oscweight_000.db #rasmus_classification_muon_3neutrino_3mio.db #dev_level7_oscNext_IC86_003.db\n",
    "        'features': 'charge_log10, dom_time, dom_x, dom_y, dom_z',\n",
    "        'targets': 'azimuth, zenith',\n",
    "        'TrTV': (0.025,0.995,1)\n",
    "       }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.033858261664001306"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf = pd.read_pickle(r'C:\\Users\\jv97\\Desktop\\github\\Neutrino-Machine-Learning\\datasets\\transformers.pkl')\n",
    "time_center, time_scale = tf['features']['time'].center_[0], tf['features']['time'].scale_[0]\n",
    "charge_center, charge_scale = tf['features']['charge_log10'].center_[0], tf['features']['charge_log10'].scale_[0]\n",
    "charge_center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "centers = pd.DataFrame({'charge_log10': [-0.033858],\n",
    "                        'dom_time': [10700.0],\n",
    "                        'dom_x': [0],\n",
    "                        'dom_y': [0],\n",
    "                        'dom_z': [0]})\n",
    "scalers = pd.DataFrame({'charge_log10': [0.274158],\n",
    "                        'dom_time': [2699.0],\n",
    "                        'dom_x': [300],\n",
    "                        'dom_y': [300],\n",
    "                        'dom_z': [300]})\n",
    "centers = centers[args['features'].split(', ')].values\n",
    "scalers = scalers[args['features'].split(', ')].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "filepath = os.path.join(path,'raw_data/dev_level7_mu_e_tau_oscweight_000/data')\n",
    "def x_transform(df):\n",
    "    df = (df - centers)/scalers\n",
    "    return torch.tensor(df.values)\n",
    "\n",
    "def y_transform(df):\n",
    "    return torch.tensor(df.values)\n",
    "\n",
    "\n",
    "\n",
    "dataset = fc.custom_db_dataset(filepath = filepath,\n",
    "                               filename = args['filename'],\n",
    "                               features = args['features'],\n",
    "                               targets = args['targets'],\n",
    "                               TrTV = args['TrTV'],\n",
    "#                                event_nos = event_nos,\n",
    "                               x_transform = x_transform,\n",
    "                               y_transform = y_transform,\n",
    "                               shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch_geometric.utils import softmax\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataset.collate(dataset[[i for i in range(512)]])\n",
    "x, batch = data.x.float(), data.batch\n",
    "graph_ids, graph_node_counts = batch.unique(return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@torch.jit.script\n",
    "def x_feature_constructor(x, graph_node_counts):\n",
    "    tmp = []\n",
    "    a : List[int] = graph_node_counts.tolist()\n",
    "    for tmp_x in x.split(a):\n",
    "        tmp_x = tmp_x.unsqueeze(1) - tmp_x\n",
    "\n",
    "        cart = tmp_x[:,:,-3:]\n",
    "\n",
    "        rho = torch.norm(cart, p=2, dim=-1).unsqueeze(2)\n",
    "        rho_mask = rho.squeeze() != 0\n",
    "        if rho_mask.sum() != 0:\n",
    "            cart[rho_mask] = cart[rho_mask] / rho[rho_mask]\n",
    "        tmp_x = torch.cat([cart,rho,tmp_x[:,:,:-3]],dim=2)\n",
    "\n",
    "        tmp.append(torch.cat([tmp_x.mean(1),tmp_x.std(1),tmp_x.min(1)[0],tmp_x.max(1)[0]],dim=1))\n",
    "    return torch.cat(tmp,0)\n",
    "x = torch.zeros((4,5))\n",
    "graph_node_counts = torch.tensor([2,2])\n",
    "\n",
    "x_feature_constructor(x, graph_node_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "act = torch.nn.SiLU()\n",
    "            \n",
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, hcs_list, act = act):\n",
    "        super(MLP, self).__init__()\n",
    "        mlp = []\n",
    "        for i in range(1,len(hcs_list)):\n",
    "            mlp.append(torch.nn.Linear(hcs_list[i-1], hcs_list[i]))\n",
    "            mlp.append(torch.nn.BatchNorm1d(hcs_list[i]))\n",
    "            mlp.append(act)\n",
    "\n",
    "        self.mlp = torch.nn.Sequential(*mlp)\n",
    "    def forward(self, x):\n",
    "        return self.mlp(x)\n",
    "\n",
    "class AttGNN(torch.nn.Module):\n",
    "    def __init__(self, hcs_in, hcs_out, act = act):\n",
    "        super(AttGNN, self).__init__()\n",
    "\n",
    "        self.beta = torch.nn.Parameter(torch.ones(1))\n",
    "\n",
    "        self.self_mlp = MLP([hcs_in,hcs_in,hcs_out])\n",
    "        self.msg_mlp = MLP([hcs_in,hcs_in,hcs_out])\n",
    "#     @torch.jit.script_method\n",
    "    def forward(self, x, graph_node_counts):\n",
    "        \n",
    "        li : List[int] = graph_node_counts.tolist()\n",
    "        \n",
    "        tmp = []\n",
    "        for tmp_x, msg in zip(x.split(li), self.msg_mlp(x).split(li)):\n",
    "            att = F.normalize(tmp_x,p=2.,dim=1)\n",
    "            att = torch.cdist(att,att)\n",
    "            tmp.append(torch.matmul(F.softmax(self.beta*att,1),msg))\n",
    "        return self.self_mlp(x) + torch.cat(tmp,0)\n",
    "    \n",
    "#         att = []\n",
    "#         for tmp_x in x.split(li):\n",
    "#             tmp_x = F.normalize(tmp_x,p=2,dim=1)\n",
    "#             tmp_x = torch.cdist(tmp_x,tmp_x)\n",
    "#             att.append(F.softmax(self.beta*tmp_x,1))\n",
    "#         return self.self_mlp(x) + torch.matmul(torch.block_diag(*att), self.msg_mlp(x))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1273, -0.0672,  0.3483,  ...,  0.1578, -0.2569, -0.2680],\n",
       "        [ 0.1665, -0.1731,  0.4215,  ...,  0.1063, -0.1538, -0.2628],\n",
       "        [ 0.1384, -0.0085,  0.3085,  ...,  0.0811, -0.1199, -0.1687],\n",
       "        ...,\n",
       "        [-0.1511,  0.1902,  0.0539,  ...,  0.0304,  0.2931,  0.6304],\n",
       "        [-0.1606,  0.1912, -0.0064,  ...,  0.0065,  0.1981,  0.7325],\n",
       "        [-0.1827,  0.2128, -0.0371,  ...,  0.0367,  0.0885,  0.5596]],\n",
       "       grad_fn=<DifferentiableGraphBackward>)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scripted = torch.jit.script(AttGNN(5,64))\n",
    "scripted(x,graph_node_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0971,  0.4304, -0.1259,  ..., -0.1390,  0.2009,  0.0365],\n",
       "        [ 0.1442,  0.4049, -0.0783,  ..., -0.0699,  0.3637,  0.1164],\n",
       "        [ 0.0099,  0.9878, -0.1357,  ...,  0.0017,  0.3984,  0.0704],\n",
       "        ...,\n",
       "        [ 0.0262, -0.2686,  0.3658,  ..., -0.1938, -0.2484, -0.0396],\n",
       "        [ 0.0267, -0.2675,  0.2868,  ..., -0.2418, -0.2501, -0.0807],\n",
       "        [ 0.4311, -0.2522,  0.3933,  ..., -0.1973, -0.2537, -0.0476]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = AttGNN(5,64)\n",
    "A(x,graph_node_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Index tensor must have the same number of dimensions as input tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-170-45e6ffd8001d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m: Index tensor must have the same number of dimensions as input tensor"
     ]
    }
   ],
   "source": [
    "torch.gather(x,-1,batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3.4501, -0.1086,  0.0457, -0.1864, -0.8372],\n",
       "        [ 3.3598, -0.1090,  0.0415, -0.1881, -0.8418],\n",
       "        [ 3.4428, -0.0911,  0.0536, -0.1820, -0.8401],\n",
       "        ...,\n",
       "        [ 3.4325, -0.1633,  0.0290, -0.1883, -1.4630],\n",
       "        [ 3.4530, -0.1633,  0.0293, -0.1890, -1.4628],\n",
       "        [ 3.5029, -0.1677,  0.0280, -0.1965, -1.4586]], dtype=torch.float64)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "def forward(x, graph_node_counts):\n",
    "    att = []\n",
    "    for tmp_x in x.split(graph_node_counts.tolist()):\n",
    "        tmp_x = F.normalize(tmp_x,p=2,dim=1)\n",
    "        tmp_x = torch.cdist(tmp_x,tmp_x)\n",
    "        att.append(F.softmax(tmp_x,1))\n",
    "    return torch.matmul(torch.block_diag(*att),x)\n",
    "graph_ids, graph_node_counts = batch.unique(return_counts=True)\n",
    "att = forward(x, graph_node_counts)\n",
    "att"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "bmm(): argument 'input' (position 1) must be Tensor, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-fc636206ecbf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph_node_counts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph_node_counts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: bmm(): argument 'input' (position 1) must be Tensor, not tuple"
     ]
    }
   ],
   "source": [
    "torch.bmm(x.split(graph_node_counts.tolist()),x.split(graph_node_counts.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function torch.nn.functional._pad(input, pad, mode='constant', value=0)>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0222, 0.0444, 0.0488,  ..., 0.0236, 0.0357, 0.0363],\n",
       "        [0.0368, 0.0184, 0.0205,  ..., 0.0357, 0.0249, 0.0246],\n",
       "        [0.0372, 0.0188, 0.0169,  ..., 0.0360, 0.0249, 0.0246],\n",
       "        ...,\n",
       "        [0.0245, 0.0447, 0.0491,  ..., 0.0230, 0.0354, 0.0360],\n",
       "        [0.0359, 0.0302, 0.0329,  ..., 0.0343, 0.0223, 0.0227],\n",
       "        [0.0361, 0.0295, 0.0321,  ..., 0.0344, 0.0224, 0.0221]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_x = dataset[0].x\n",
    "tmp_x = F.normalize(tmp_x,p=2,dim=1)\n",
    "tmp_x = torch.cdist(tmp_x,tmp_x)\n",
    "tmp_x = F.softmax(tmp_x,1)\n",
    "tmp_x\n",
    "# tmp_x = tmp_x.unsqueeze(1) - 0*tmp_x\n",
    "# tmp_x\n",
    "\n",
    "# tmp_x = F.normalize(tmp_x, p=2, dim=2)\n",
    "\n",
    "# torch.matmul(tmp_x.unsqueeze(2),tmp_x.unsqueeze(3)).squeeze()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
