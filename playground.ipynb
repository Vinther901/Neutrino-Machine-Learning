{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.special import iv\n",
    "import numpy as np\n",
    "\n",
    "def df_to_csv(df,filename):\n",
    "    in_columns = ['event_no','azimuth_pred','zenith_pred']#,'azimuth_pred_sigma','zenith_pred_sigma']\n",
    "    out_columns = ['event_no','azimuth_pred','zenith_pred','azimuth_sigma','zenith_sigma']\n",
    "    \n",
    "    R_az = iv(1,np.square(df.azimuth_pred_sigma))/iv(0,np.square(df.azimuth_pred_sigma))\n",
    "    R_ze = iv(1,np.square(df.zenith_pred_sigma))/iv(0,np.square(df.zenith_pred_sigma))\n",
    "\n",
    "    # az_sigma = np.sqrt(1 - R_az)\n",
    "    # ze_sigma = np.sqrt(1 - R_ze)\n",
    "\n",
    "    az_sigma = np.sqrt(-2*np.log(R_az))\n",
    "    ze_sigma = np.sqrt(-2*np.log(R_ze))\n",
    "    \n",
    "    tmp = pd.DataFrame(pd.concat([df[in_columns],az_sigma,ze_sigma],1).values,columns=out_columns)\n",
    "    tmp.to_csv('predictions/{}.csv'.format(filename))\n",
    "\n",
    "# mc = pd.read_pickle('predictions/test_predictions.pkl')\n",
    "# data = pd.read_pickle('predictions/test_data_predictions.pkl')\n",
    "\n",
    "# df_to_csv(mc,'GGConv_1mio_MC_predictions01')\n",
    "# df_to_csv(data,'GGConv_data_predictions01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import pandas as pd\n",
    "import time\n",
    "import wandb\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "import FunctionCollection as fc\n",
    "import importlib\n",
    "fc = importlib.reload(fc)\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'C:\\Users\\jv97\\Desktop\\github\\Neutrino-Machine-Learning'\n",
    "\n",
    "run_name = 'oscNext_angle_m9'\n",
    "\n",
    "args = {'N_edge_feats': 6,\n",
    "        'N_dom_feats': 4,\n",
    "        'N_targets': 2,\n",
    "        'N_outputs': 4,\n",
    "        'N_metalayers': 1,\n",
    "        'N_hcs': 64,\n",
    "        'diagonal_cov': True,\n",
    "        'wandb_activated': False,\n",
    "        'type': 'twice_Polar_NLLH',\n",
    "        'zenith': True,\n",
    "        'id': wandb.util.generate_id()[:4],\n",
    "        'eps': 0,\n",
    "        'lr': 0.0209,\n",
    "        'filename': 'dev_level7_mu_e_tau_oscweight_000_unscaled.db',#dev_level7_mu_e_tau_oscweight_000.db #rasmus_classification_muon_3neutrino_3mio.db #dev_level7_oscNext_IC86_003.db\n",
    "        'features': 'dom_time, dom_x, dom_y, dom_z',\n",
    "        'targets': 'azimuth, zenith',\n",
    "        'TrTV': (0.025,0.995,1)\n",
    "       }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.033858261664001306"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf = pd.read_pickle(r'C:\\Users\\jv97\\Desktop\\github\\Neutrino-Machine-Learning\\datasets\\transformers.pkl')\n",
    "time_center, time_scale = tf['features']['time'].center_[0], tf['features']['time'].scale_[0]\n",
    "charge_center, charge_scale = tf['features']['charge_log10'].center_[0], tf['features']['charge_log10'].scale_[0]\n",
    "charge_center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "centers = pd.DataFrame({'charge_log10': [-0.033858],\n",
    "                        'dom_time': [10700.0],\n",
    "                        'dom_x': [0],\n",
    "                        'dom_y': [0],\n",
    "                        'dom_z': [0]})\n",
    "scalers = pd.DataFrame({'charge_log10': [0.274158],\n",
    "                        'dom_time': [2699.0],\n",
    "                        'dom_x': [300],\n",
    "                        'dom_y': [300],\n",
    "                        'dom_z': [300]})\n",
    "centers = centers[args['features'].split(', ')].values\n",
    "scalers = scalers[args['features'].split(', ')].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.jit.script\n",
    "def x_feature_constructor(x, graph_node_counts):\n",
    "    tmp = []\n",
    "    a : List[int] = graph_node_counts.tolist()\n",
    "    for tmp_x in x.split(a):\n",
    "        tmp_x = tmp_x.unsqueeze(1) - tmp_x\n",
    "\n",
    "        cart = tmp_x[:,:,-3:]\n",
    "\n",
    "        rho = torch.norm(cart, p=2, dim=-1).unsqueeze(2)\n",
    "        rho_mask = rho.squeeze() != 0\n",
    "        if rho_mask.sum() != 0:\n",
    "            cart[rho_mask] = cart[rho_mask] / rho[rho_mask]\n",
    "        tmp_x = torch.cat([cart,rho,tmp_x[:,:,:-3]],dim=2)\n",
    "\n",
    "        tmp.append(torch.cat([tmp_x.mean(1),tmp_x.std(1),tmp_x.min(1)[0],tmp_x.max(1)[0]],dim=1))\n",
    "    return torch.cat(tmp,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "filepath = os.path.join(path,'raw_data/dev_level7_mu_e_tau_oscweight_000/data')\n",
    "def x_transform(df):\n",
    "    df = (df - centers)/scalers\n",
    "    return torch.tensor(df.values)\n",
    "\n",
    "def y_transform(df):\n",
    "    return torch.tensor(df.values)\n",
    "\n",
    "# import dill\n",
    "# with open('AzZe_Muon_bin_reweighter.pkl','rb') as file:\n",
    "#     reweighter = dill.load(file)\n",
    "\n",
    "dataset = fc.custom_db_dataset(filepath = filepath,\n",
    "                               filename = args['filename'],\n",
    "                               features = args['features'],\n",
    "                               targets = args['targets'],\n",
    "                               TrTV = args['TrTV'],\n",
    "#                                event_nos = event_nos,\n",
    "                               x_transform = x_transform,\n",
    "                               y_transform = y_transform,\n",
    "                               shuffle = True,\n",
    "#                                reweighter = reweighter\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([25, 25, 8]), torch.Size([25, 25, 5]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "li = torch.nn.Linear(args['N_dom_feats']*2,5)\n",
    "# norm = torch.nn.BatchNorm2d(5)\n",
    "tmp_x = dataset[0].x.float()\n",
    "tmp_x = torch.cat([tmp_x.unsqueeze(1) - tmp_x, tmp_x.unsqueeze(1) + tmp_x],dim=2)\n",
    "tmp_x.shape, li(tmp_x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'dim'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-16ff85e88497>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mtmp_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mtmp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtmp_x\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mtmp_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtmp_x\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtmp_x\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mli\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1686\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mTensor\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtens_ops\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mhas_torch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtens_ops\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1687\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtens_ops\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1688\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1689\u001b[0m         \u001b[1;31m# fused op is marginally faster\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1690\u001b[0m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'dim'"
     ]
    }
   ],
   "source": [
    "tmp = []\n",
    "for i in range(2):\n",
    "    tmp_x = dataset[0].x.float()\n",
    "    tmp.append(torch.cat([tmp_x.unsqueeze(1) - tmp_x, tmp_x.unsqueeze(1) + tmp_x],dim=2))\n",
    "li(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_loader, test_loader, val_loader = dataset.return_dataloaders(batch_size=2)\n",
    "for dat in train_loader:\n",
    "    break\n",
    "# import Model_Loaders.Model_13 as M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_geometric\n",
    "T = torch_geometric.nn.TransformerConv(in_channels = [4,4],\n",
    "                                       out_channels = 1,\n",
    "                                       heads = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
       "         36],\n",
       "        [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# def return_edge_index(batch):\n",
    "\n",
    "edge_index = torch.cat([torch.zeros(dat.x.shape[0],dtype=torch.long).view(1,-1),\n",
    "                        torch.arange(dat.x.shape[0],dtype=torch.long).view(1,-1)],dim=0)\n",
    "edge_index = edge_index.flip(0).contiguous()\n",
    "edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4254,  0.2978,  0.6247,  0.5012],\n",
       "        [-0.5813, -1.1389, -1.3015,  0.7955]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_CoC[dat.batch.unique()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_edge_index(batch):\n",
    "    offset = batch.max() + 1\n",
    "    frm = torch.arange(offset, offset + batch.shape[0],dtype=torch.long).view(1,-1)\n",
    "    to = batch.view(1,-1)\n",
    "    return torch.cat([frm,to],dim=0).contiguous()\n",
    "\n",
    "edge_index = return_edge_index(dat.batch)\n",
    "CoC = torch.randn(2,4).float()\n",
    "x_CoC = torch.cat([CoC,dat.x.float()],dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-8.1741e-01,  2.0260e-01, -3.2949e-01,  8.7144e-02],\n",
       "         [ 4.5862e-01, -3.3051e-01, -2.5118e-01,  7.8639e-01],\n",
       "         [-1.0140e-01,  1.6002e-01, -4.3665e-01,  1.1924e-01],\n",
       "         [ 4.3814e-02,  1.7031e-01, -4.2947e-01,  5.6311e-02],\n",
       "         [ 8.5492e-02,  1.7097e-01, -4.3542e-01,  3.1548e-02],\n",
       "         [ 1.5709e-01,  1.7060e-01, -4.5094e-01, -1.5432e-02],\n",
       "         [ 1.8104e-01,  1.6870e-01, -4.6235e-01, -3.6355e-02],\n",
       "         [-8.7739e-02,  1.4496e-01, -5.1044e-01,  9.1376e-02],\n",
       "         [-8.2993e-02,  1.4123e-01, -5.2446e-01,  7.7388e-02],\n",
       "         [-1.2892e-01,  1.6549e-01, -5.1061e-01,  5.4304e-02],\n",
       "         [-2.6902e-01,  2.5011e-01, -4.9826e-01, -2.3644e-02],\n",
       "         [-9.7558e-02,  2.0922e-01, -4.4288e-01,  4.0228e-02],\n",
       "         [ 2.2945e-03,  2.0379e-01, -4.8176e-01, -3.9718e-02],\n",
       "         [-1.1423e-03,  2.0329e-01, -4.8282e-01, -3.8973e-02],\n",
       "         [ 6.4763e-03,  2.0218e-01, -4.8821e-01, -4.7104e-02],\n",
       "         [-2.7711e-02,  1.9723e-01, -4.9875e-01, -3.9697e-02],\n",
       "         [ 2.4440e-02,  1.9815e-01, -5.0589e-01, -7.0427e-02],\n",
       "         [-3.4826e-02,  1.8295e-01, -5.4739e-01, -7.7027e-02],\n",
       "         [ 1.3853e-02,  1.8778e-01, -5.4012e-01, -9.4054e-02],\n",
       "         [ 9.4460e-03,  1.6533e-01, -4.4007e-01,  6.3757e-02],\n",
       "         [-3.6636e-02,  1.9722e-01, -4.6574e-01,  4.0478e-02],\n",
       "         [-2.4007e-02,  1.6745e-01, -4.4435e-01,  1.1644e-01],\n",
       "         [-1.0962e-02,  1.6712e-01, -4.4807e-01,  1.0713e-01],\n",
       "         [ 1.1184e-02,  1.6149e-01, -4.7220e-01,  7.6424e-02],\n",
       "         [ 4.7201e-02,  1.6449e-01, -4.6883e-01,  6.2140e-02],\n",
       "         [ 4.5393e-02,  1.6423e-01, -4.6939e-01,  6.2532e-02],\n",
       "         [ 4.2860e-02,  1.6387e-01, -4.7017e-01,  6.3081e-02],\n",
       "         [ 5.7172e-02,  1.6373e-01, -4.7350e-01,  5.3500e-02],\n",
       "         [ 5.5182e-02,  1.6344e-01, -4.7412e-01,  5.3931e-02],\n",
       "         [ 5.3373e-02,  1.6318e-01, -4.7467e-01,  5.4323e-02],\n",
       "         [ 2.4612e-02,  1.5901e-01, -4.8354e-01,  6.0554e-02],\n",
       "         [ 6.3003e-02,  1.6015e-01, -4.8719e-01,  3.9276e-02],\n",
       "         [ 3.5788e-02,  1.4516e-01, -5.3428e-01,  1.2781e-02],\n",
       "         [-3.8079e-02,  1.9410e-01, -4.2842e-01,  7.9974e-02],\n",
       "         [-2.9375e-02,  1.9315e-01, -4.3348e-01,  7.1608e-02],\n",
       "         [-1.9628e-04,  1.9075e-01, -4.4770e-01,  4.5855e-02],\n",
       "         [-4.7600e-02,  1.3811e-01, -4.6179e-01,  1.6959e-01],\n",
       "         [-1.3841e-01,  1.0509e-01, -5.5945e-01,  1.3096e-01],\n",
       "         [ 5.4457e-02,  1.2858e-01, -5.1547e-01,  7.6210e-02]],\n",
       "        grad_fn=<AsStridedBackward>),\n",
       " tensor([[-1.0140e-01,  1.6002e-01, -4.3665e-01,  1.1924e-01],\n",
       "         [ 4.3814e-02,  1.7031e-01, -4.2947e-01,  5.6311e-02],\n",
       "         [ 8.5492e-02,  1.7097e-01, -4.3542e-01,  3.1548e-02],\n",
       "         [ 1.5709e-01,  1.7060e-01, -4.5094e-01, -1.5432e-02],\n",
       "         [ 1.8104e-01,  1.6870e-01, -4.6235e-01, -3.6355e-02],\n",
       "         [-8.7739e-02,  1.4496e-01, -5.1044e-01,  9.1376e-02],\n",
       "         [-8.2993e-02,  1.4123e-01, -5.2446e-01,  7.7388e-02],\n",
       "         [-1.2892e-01,  1.6549e-01, -5.1061e-01,  5.4304e-02],\n",
       "         [-2.6902e-01,  2.5011e-01, -4.9826e-01, -2.3644e-02],\n",
       "         [-9.7558e-02,  2.0922e-01, -4.4288e-01,  4.0228e-02],\n",
       "         [ 2.2945e-03,  2.0379e-01, -4.8176e-01, -3.9718e-02],\n",
       "         [-1.1423e-03,  2.0329e-01, -4.8282e-01, -3.8973e-02],\n",
       "         [ 6.4763e-03,  2.0218e-01, -4.8821e-01, -4.7104e-02],\n",
       "         [-2.7711e-02,  1.9723e-01, -4.9875e-01, -3.9697e-02],\n",
       "         [ 2.4440e-02,  1.9815e-01, -5.0589e-01, -7.0427e-02],\n",
       "         [-3.4826e-02,  1.8295e-01, -5.4739e-01, -7.7027e-02],\n",
       "         [ 1.3853e-02,  1.8778e-01, -5.4012e-01, -9.4054e-02],\n",
       "         [ 9.4460e-03,  1.6533e-01, -4.4007e-01,  6.3757e-02],\n",
       "         [-3.6636e-02,  1.9722e-01, -4.6574e-01,  4.0478e-02],\n",
       "         [-2.4007e-02,  1.6745e-01, -4.4435e-01,  1.1644e-01],\n",
       "         [-1.0962e-02,  1.6712e-01, -4.4807e-01,  1.0713e-01],\n",
       "         [ 1.1184e-02,  1.6149e-01, -4.7220e-01,  7.6424e-02],\n",
       "         [ 4.7201e-02,  1.6449e-01, -4.6883e-01,  6.2140e-02],\n",
       "         [ 4.5393e-02,  1.6423e-01, -4.6939e-01,  6.2532e-02],\n",
       "         [ 4.2860e-02,  1.6387e-01, -4.7017e-01,  6.3081e-02],\n",
       "         [ 5.7172e-02,  1.6373e-01, -4.7350e-01,  5.3500e-02],\n",
       "         [ 5.5182e-02,  1.6344e-01, -4.7412e-01,  5.3931e-02],\n",
       "         [ 5.3373e-02,  1.6318e-01, -4.7467e-01,  5.4323e-02],\n",
       "         [ 2.4612e-02,  1.5901e-01, -4.8354e-01,  6.0554e-02],\n",
       "         [ 6.3003e-02,  1.6015e-01, -4.8719e-01,  3.9276e-02],\n",
       "         [ 3.5788e-02,  1.4516e-01, -5.3428e-01,  1.2781e-02],\n",
       "         [-3.8079e-02,  1.9410e-01, -4.2842e-01,  7.9974e-02],\n",
       "         [-2.9375e-02,  1.9315e-01, -4.3348e-01,  7.1608e-02],\n",
       "         [-1.9628e-04,  1.9075e-01, -4.4770e-01,  4.5855e-02],\n",
       "         [-4.7600e-02,  1.3811e-01, -4.6179e-01,  1.6959e-01],\n",
       "         [-1.3841e-01,  1.0509e-01, -5.5945e-01,  1.3096e-01],\n",
       "         [ 5.4457e-02,  1.2858e-01, -5.1547e-01,  7.6210e-02]],\n",
       "        grad_fn=<AddmmBackward>))"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T(x_CoC,edge_index), T.lin_skip(dat.x.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.1695],\n",
       "         [ 0.0419],\n",
       "         [ 0.0066],\n",
       "         [-0.0532],\n",
       "         [-0.0722],\n",
       "         [ 0.2153],\n",
       "         [ 0.2134],\n",
       "         [ 0.1609],\n",
       "         [ 0.0109],\n",
       "         [ 0.0335],\n",
       "         [-0.0471],\n",
       "         [-0.0440],\n",
       "         [-0.0497],\n",
       "         [-0.0183],\n",
       "         [-0.0625],\n",
       "         [-0.0042],\n",
       "         [-0.0478],\n",
       "         [ 0.0735],\n",
       "         [ 0.0521],\n",
       "         [ 0.1491],\n",
       "         [ 0.1383],\n",
       "         [ 0.1230],\n",
       "         [ 0.0911],\n",
       "         [ 0.0927],\n",
       "         [ 0.0951],\n",
       "         [ 0.0831],\n",
       "         [ 0.0850],\n",
       "         [ 0.0866],\n",
       "         [ 0.1131],\n",
       "         [ 0.0803],\n",
       "         [ 0.1116],\n",
       "         [ 0.0686],\n",
       "         [ 0.0618],\n",
       "         [ 0.0387],\n",
       "         [ 0.2628],\n",
       "         [ 0.3576],\n",
       "         [ 0.1827]], grad_fn=<AddmmBackward>),\n",
       " tensor([[0.5869],\n",
       "         [0.4593],\n",
       "         [0.4240],\n",
       "         [0.3642],\n",
       "         [0.3452],\n",
       "         [0.6327],\n",
       "         [0.6308],\n",
       "         [0.5784],\n",
       "         [0.4284],\n",
       "         [0.4509],\n",
       "         [0.3703],\n",
       "         [0.3734],\n",
       "         [0.3677],\n",
       "         [0.3991],\n",
       "         [0.3549],\n",
       "         [0.4132],\n",
       "         [0.3696],\n",
       "         [0.4909],\n",
       "         [0.4695],\n",
       "         [0.5665],\n",
       "         [0.5558],\n",
       "         [0.5404],\n",
       "         [0.5085],\n",
       "         [0.5102],\n",
       "         [0.5125],\n",
       "         [0.5006],\n",
       "         [0.5024],\n",
       "         [0.5041],\n",
       "         [0.5305],\n",
       "         [0.4977],\n",
       "         [0.5290],\n",
       "         [0.4860],\n",
       "         [0.4792],\n",
       "         [0.4561],\n",
       "         [0.6802],\n",
       "         [0.7751],\n",
       "         [0.6001]], grad_fn=<AsStridedBackward>))"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T.lin_skip(dat.x.float()), T(dat.x.float(),edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 9.6332e-02,  4.1657e-01, -4.3750e-01, -9.6433e-01],\n",
       "         [-1.4153e-01,  4.1657e-01, -4.3750e-01, -1.0778e+00],\n",
       "         [-1.9711e-01,  4.1657e-01, -4.3750e-01, -1.1345e+00],\n",
       "         [-2.8418e-01,  4.1657e-01, -4.3750e-01, -1.2480e+00],\n",
       "         [-3.0345e-01,  4.1657e-01, -4.3750e-01, -1.3047e+00],\n",
       "         [-1.5561e-02,  1.0417e-01, -2.4310e-01, -9.7430e-01],\n",
       "         [-7.4102e-04,  1.0417e-01, -2.4310e-01, -1.0210e+00],\n",
       "         [ 5.8540e-02,  2.4123e-01, -2.2200e-01, -1.0467e+00],\n",
       "         [ 4.0015e-02,  3.5647e-01,  9.0300e-02, -1.0031e+00],\n",
       "         [-8.7810e-02,  3.7730e-01, -2.0157e-01, -9.8087e-01],\n",
       "         [-1.8192e-01,  3.7730e-01, -2.0157e-01, -1.1911e+00],\n",
       "         [-1.7488e-01,  3.7730e-01, -2.0157e-01, -1.1911e+00],\n",
       "         [-1.7821e-01,  3.7730e-01, -2.0157e-01, -1.2145e+00],\n",
       "         [-1.0819e-01,  3.7730e-01, -2.0157e-01, -1.2145e+00],\n",
       "         [-1.7821e-01,  3.7730e-01, -2.0157e-01, -1.2846e+00],\n",
       "         [-2.0007e-02,  3.7730e-01, -2.0157e-01, -1.3547e+00],\n",
       "         [-1.0745e-01,  3.7730e-01, -2.0157e-01, -1.3780e+00],\n",
       "         [-7.1137e-02,  4.1657e-01, -4.3750e-01, -1.0778e+00],\n",
       "         [-2.5380e-01,  1.5430e-01, -1.1627e-01, -9.3993e-01],\n",
       "         [-2.1971e-01,  1.0417e-01, -2.4310e-01, -8.3413e-01],\n",
       "         [-2.3416e-01,  1.0417e-01, -2.4310e-01, -8.5750e-01],\n",
       "         [-2.3046e-01,  1.0417e-01, -2.4310e-01, -9.5093e-01],\n",
       "         [-2.9196e-01,  1.0417e-01, -2.4310e-01, -9.7430e-01],\n",
       "         [-2.8825e-01,  1.0417e-01, -2.4310e-01, -9.7430e-01],\n",
       "         [-2.8307e-01,  1.0417e-01, -2.4310e-01, -9.7430e-01],\n",
       "         [-3.0011e-01,  1.0417e-01, -2.4310e-01, -9.9767e-01],\n",
       "         [-2.9604e-01,  1.0417e-01, -2.4310e-01, -9.9767e-01],\n",
       "         [-2.9233e-01,  1.0417e-01, -2.4310e-01, -9.9767e-01],\n",
       "         [-2.3342e-01,  1.0417e-01, -2.4310e-01, -9.9767e-01],\n",
       "         [-2.8751e-01,  1.0417e-01, -2.4310e-01, -1.0444e+00],\n",
       "         [-1.7043e-01,  1.0417e-01, -2.4310e-01, -1.1612e+00],\n",
       "         [-2.1341e-01,  2.4123e-01, -2.2200e-01, -8.8320e-01],\n",
       "         [-2.1897e-01,  2.4123e-01, -2.2200e-01, -9.0657e-01],\n",
       "         [-2.4194e-01,  2.4123e-01, -2.2200e-01, -9.7663e-01],\n",
       "         [-1.6413e-01, -3.2267e-02, -2.6500e-01, -7.5500e-01],\n",
       "         [ 1.3227e-01, -3.2267e-02, -2.6500e-01, -9.6523e-01],\n",
       "         [-2.3824e-01, -3.2267e-02, -2.6500e-01, -1.0120e+00]],\n",
       "        dtype=torch.float64),\n",
       " tensor([[ 0.6118],\n",
       "         [ 0.0419],\n",
       "         [ 0.0066],\n",
       "         [-0.0532],\n",
       "         [-0.0722],\n",
       "         [ 0.2153],\n",
       "         [ 0.2134],\n",
       "         [ 0.1609],\n",
       "         [ 0.0109],\n",
       "         [ 0.0335],\n",
       "         [-0.0471],\n",
       "         [-0.0440],\n",
       "         [-0.0497],\n",
       "         [-0.0183],\n",
       "         [-0.0625],\n",
       "         [-0.0042],\n",
       "         [-0.0478],\n",
       "         [ 0.0735],\n",
       "         [ 0.0521],\n",
       "         [ 0.1491],\n",
       "         [ 0.1383],\n",
       "         [ 0.1230],\n",
       "         [ 0.0911],\n",
       "         [ 0.0927],\n",
       "         [ 0.0951],\n",
       "         [ 0.0831],\n",
       "         [ 0.0850],\n",
       "         [ 0.0866],\n",
       "         [ 0.1131],\n",
       "         [ 0.0803],\n",
       "         [ 0.1116],\n",
       "         [ 0.0686],\n",
       "         [ 0.0618],\n",
       "         [ 0.0387],\n",
       "         [ 0.2628],\n",
       "         [ 0.3576],\n",
       "         [ 0.1827]], grad_fn=<AsStridedBackward>))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat.x,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = dat.x[dat.batch==0]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.hist(x[:,0]);\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "# ax.plot(x[:,0].cumsum(0));\n",
    "ax.plot(x[:,0],'b.');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.6737, dtype=torch.float64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1 = x[:,0].min()\n",
    "\n",
    "\n",
    "\n",
    "# from torch_scatter import scatter_min\n",
    "# scatter_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def scatter_distribution(src, index):\n",
    "    quantiles = torch.tensor([0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edge_feature_constructor(x, edge_index):\n",
    "    (frm, to) = edge_index\n",
    "    pos = x[:,2:5]\n",
    "    cart = pos[frm] - pos[to]\n",
    "\n",
    "    rho = torch.norm(cart, p=2, dim=-1).view(-1, 1)\n",
    "    rho_mask = rho.squeeze() != 0\n",
    "    cart[rho_mask] = cart[rho_mask] / rho[rho_mask]\n",
    "\n",
    "    diff = x[to,\n",
    "\n",
    "    return torch.cat([cart.type_as(pos),rho,diff.view(-1,1)], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import torch_rbf as rbf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4.0044e-07, 4.6944e-09, 1.4559e-11],\n",
       "        [2.0413e-02, 8.7443e-04, 6.4163e-06],\n",
       "        [1.0139e-05, 2.7420e-07, 1.5538e-09],\n",
       "        [3.1429e-08, 2.4587e-10, 5.4322e-13],\n",
       "        [1.2205e-04, 6.0389e-06, 9.6715e-08],\n",
       "        [3.0459e-06, 5.2546e-08, 4.0009e-10],\n",
       "        [3.3682e-07, 3.1174e-09, 1.5569e-11],\n",
       "        [9.3522e-08, 6.3208e-10, 2.9889e-12],\n",
       "        [1.4034e-08, 8.1904e-11, 6.6472e-14],\n",
       "        [3.9707e-04, 2.1994e-05, 2.6428e-07],\n",
       "        [6.6852e-03, 2.7228e-03, 1.0633e-04],\n",
       "        [4.9143e-03, 2.3263e-04, 8.4992e-06],\n",
       "        [4.3146e-10, 5.4526e-13, 9.1379e-16],\n",
       "        [4.0079e-12, 1.0589e-14, 3.9780e-18],\n",
       "        [8.2887e-09, 7.6167e-11, 1.0094e-13],\n",
       "        [3.0781e-08, 3.0946e-10, 5.8683e-13],\n",
       "        [2.5584e-03, 5.7336e-04, 2.2679e-05],\n",
       "        [1.8160e-06, 7.6619e-09, 3.2777e-12],\n",
       "        [1.1030e-02, 5.9272e-04, 5.4604e-06],\n",
       "        [9.4618e-08, 1.4609e-10, 1.6261e-13],\n",
       "        [7.3328e-05, 4.1299e-07, 1.8392e-09],\n",
       "        [1.9388e-04, 3.0278e-06, 6.2106e-09],\n",
       "        [5.2259e-11, 4.5033e-14, 1.1394e-17],\n",
       "        [1.3561e-06, 1.6059e-08, 3.6808e-11],\n",
       "        [1.7043e-15, 1.4277e-19, 8.8276e-23]], dtype=torch.float64,\n",
       "       grad_fn=<ExpBackward>)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RBF = rbf.RBF(5,3,rbf.basis_func_dict()['gaussian'])\n",
    "dat.x.shape\n",
    "RBF(dat.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remember all accuracies are positive and defined to go towards 0 in the optimal case.\n",
      "This model assumes Charge is at index 0 and position is the last three\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': tensor(0.0077, dtype=torch.float64, grad_fn=<DivBackward0>)}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Net = M.Load_model(args['type'],args)\n",
    "model = Net()\n",
    "model.training_step(dat,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch_geometric.utils import softmax\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataset.collate(dataset[[i for i in range(512)]])\n",
    "x, batch = data.x.float(), data.batch\n",
    "graph_ids, graph_node_counts = batch.unique(return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Batch(batch=[12583], x=[12583, 5], y=[1024])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3294, -0.5722,  0.5779,  ...,  0.8071,  3.6475,  0.5587],\n",
       "        [-0.4025, -0.7209, -0.2180,  ...,  0.7179,  2.9180,  0.3420],\n",
       "        [-0.0862,  0.3444, -0.4567,  ...,  0.6913,  3.1004,  0.8470],\n",
       "        ...,\n",
       "        [-0.0094,  0.8598,  0.0098,  ...,  0.4343,  2.5533,  0.3268],\n",
       "        [-0.7037, -0.2331,  0.1262,  ...,  0.4197,  2.1885,  0.0000],\n",
       "        [-0.6462, -0.2209, -0.4449,  ...,  0.4343,  1.2766,  0.3735]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@torch.jit.script\n",
    "def x_feature_constructor(x, graph_node_counts):\n",
    "    tmp = []\n",
    "    a : List[int] = graph_node_counts.tolist()\n",
    "    for tmp_x in x.split(a):\n",
    "        tmp_x = tmp_x.unsqueeze(1) - tmp_x\n",
    "\n",
    "        cart = tmp_x[:,:,-3:]\n",
    "\n",
    "        rho = torch.norm(cart, p=2, dim=-1).unsqueeze(2)\n",
    "        rho_mask = rho.squeeze() != 0\n",
    "        if rho_mask.sum() != 0:\n",
    "            cart[rho_mask] = cart[rho_mask] / rho[rho_mask]\n",
    "        tmp_x = torch.cat([cart,rho,tmp_x[:,:,:-3]],dim=2)\n",
    "\n",
    "        tmp.append(torch.cat([tmp_x.mean(1),tmp_x.std(1),tmp_x.min(1)[0],tmp_x.max(1)[0]],dim=1))\n",
    "    return torch.cat(tmp,0)\n",
    "# x = torch.zeros((4,5))\n",
    "# graph_node_counts = torch.tensor([2,2])\n",
    "\n",
    "x_feature_constructor(x, graph_node_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(38)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def FC_edge_index(batch):\n",
    "    graph_ids, graph_node_counts = batch.unique(return_counts=True)\n",
    "    starts = torch.cumsum(torch.cat([torch.zeros(1,dtype=torch.long),graph_node_counts],dim=0),dim=0)\n",
    "    \n",
    "    edge_index = torch.cat([torch.combinations(torch.arange(start,start+length)) for start, length in zip(starts[:-1],graph_node_counts)],dim=0)\n",
    "    return torch.cat([edge_index,edge_index.flip(1)]).T\n",
    "\n",
    "edge_index = FC_edge_index(data.batch)\n",
    "(edge_index == 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Data in module torch_geometric.data.data:\n",
      "\n",
      "class Data(builtins.object)\n",
      " |  Data(x=None, edge_index=None, edge_attr=None, y=None, pos=None, normal=None, face=None, **kwargs)\n",
      " |  \n",
      " |  A plain old python object modeling a single graph with various\n",
      " |  (optional) attributes:\n",
      " |  \n",
      " |  Args:\n",
      " |      x (Tensor, optional): Node feature matrix with shape :obj:`[num_nodes,\n",
      " |          num_node_features]`. (default: :obj:`None`)\n",
      " |      edge_index (LongTensor, optional): Graph connectivity in COO format\n",
      " |          with shape :obj:`[2, num_edges]`. (default: :obj:`None`)\n",
      " |      edge_attr (Tensor, optional): Edge feature matrix with shape\n",
      " |          :obj:`[num_edges, num_edge_features]`. (default: :obj:`None`)\n",
      " |      y (Tensor, optional): Graph or node targets with arbitrary shape.\n",
      " |          (default: :obj:`None`)\n",
      " |      pos (Tensor, optional): Node position matrix with shape\n",
      " |          :obj:`[num_nodes, num_dimensions]`. (default: :obj:`None`)\n",
      " |      normal (Tensor, optional): Normal vector matrix with shape\n",
      " |          :obj:`[num_nodes, num_dimensions]`. (default: :obj:`None`)\n",
      " |      face (LongTensor, optional): Face adjacency matrix with shape\n",
      " |          :obj:`[3, num_faces]`. (default: :obj:`None`)\n",
      " |  \n",
      " |  The data object is not restricted to these attributes and can be extented\n",
      " |  by any other additional data.\n",
      " |  \n",
      " |  Example::\n",
      " |  \n",
      " |      data = Data(x=x, edge_index=edge_index)\n",
      " |      data.train_idx = torch.tensor([...], dtype=torch.long)\n",
      " |      data.test_mask = torch.tensor([...], dtype=torch.bool)\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __apply__(self, item, func)\n",
      " |  \n",
      " |  __call__(self, *keys)\n",
      " |      Iterates over all attributes :obj:`*keys` in the data, yielding\n",
      " |      their attribute names and content.\n",
      " |      If :obj:`*keys` is not given this method will iterative over all\n",
      " |      present attributes.\n",
      " |  \n",
      " |  __cat_dim__(self, key, value)\n",
      " |      Returns the dimension for which :obj:`value` of attribute\n",
      " |      :obj:`key` will get concatenated when creating batches.\n",
      " |      \n",
      " |      .. note::\n",
      " |      \n",
      " |          This method is for internal use only, and should only be overridden\n",
      " |          if the batch concatenation process is corrupted for a specific data\n",
      " |          attribute.\n",
      " |  \n",
      " |  __contains__(self, key)\n",
      " |      Returns :obj:`True`, if the attribute :obj:`key` is present in the\n",
      " |      data.\n",
      " |  \n",
      " |  __getitem__(self, key)\n",
      " |      Gets the data of the attribute :obj:`key`.\n",
      " |  \n",
      " |  __inc__(self, key, value)\n",
      " |      Returns the incremental count to cumulatively increase the value\n",
      " |      of the next attribute of :obj:`key` when creating batches.\n",
      " |      \n",
      " |      .. note::\n",
      " |      \n",
      " |          This method is for internal use only, and should only be overridden\n",
      " |          if the batch concatenation process is corrupted for a specific data\n",
      " |          attribute.\n",
      " |  \n",
      " |  __init__(self, x=None, edge_index=None, edge_attr=None, y=None, pos=None, normal=None, face=None, **kwargs)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  __iter__(self)\n",
      " |      Iterates over all present attributes in the data, yielding their\n",
      " |      attribute names and content.\n",
      " |  \n",
      " |  __len__(self)\n",
      " |      Returns the number of all present attributes.\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setitem__(self, key, value)\n",
      " |      Sets the attribute :obj:`key` to :obj:`value`.\n",
      " |  \n",
      " |  apply(self, func, *keys)\n",
      " |      Applies the function :obj:`func` to all tensor attributes\n",
      " |      :obj:`*keys`. If :obj:`*keys` is not given, :obj:`func` is applied to\n",
      " |      all present attributes.\n",
      " |  \n",
      " |  clone(self)\n",
      " |  \n",
      " |  coalesce(self)\n",
      " |      \"Orders and removes duplicated entries from edge indices.\n",
      " |  \n",
      " |  contains_isolated_nodes(self)\n",
      " |      Returns :obj:`True`, if the graph contains isolated nodes.\n",
      " |  \n",
      " |  contains_self_loops(self)\n",
      " |      Returns :obj:`True`, if the graph contains self-loops.\n",
      " |  \n",
      " |  contiguous(self, *keys)\n",
      " |      Ensures a contiguous memory layout for all attributes :obj:`*keys`.\n",
      " |      If :obj:`*keys` is not given, all present attributes are ensured to\n",
      " |      have a contiguous memory layout.\n",
      " |  \n",
      " |  debug(self)\n",
      " |  \n",
      " |  is_coalesced(self)\n",
      " |      Returns :obj:`True`, if edge indices are ordered and do not contain\n",
      " |      duplicate entries.\n",
      " |  \n",
      " |  is_directed(self)\n",
      " |      Returns :obj:`True`, if graph edges are directed.\n",
      " |  \n",
      " |  is_undirected(self)\n",
      " |      Returns :obj:`True`, if graph edges are undirected.\n",
      " |  \n",
      " |  to(self, device, *keys, **kwargs)\n",
      " |      Performs tensor dtype and/or device conversion to all attributes\n",
      " |      :obj:`*keys`.\n",
      " |      If :obj:`*keys` is not given, the conversion is applied to all present\n",
      " |      attributes.\n",
      " |  \n",
      " |  to_dict(self)\n",
      " |  \n",
      " |  to_namedtuple(self)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods defined here:\n",
      " |  \n",
      " |  from_dict(dictionary) from builtins.type\n",
      " |      Creates a data object from a python dictionary.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  keys\n",
      " |      Returns all names of graph attributes.\n",
      " |  \n",
      " |  num_edge_features\n",
      " |      Returns the number of features per edge in the graph.\n",
      " |  \n",
      " |  num_edges\n",
      " |      Returns the number of edges in the graph.\n",
      " |  \n",
      " |  num_faces\n",
      " |      Returns the number of faces in the mesh.\n",
      " |  \n",
      " |  num_features\n",
      " |      Alias for :py:attr:`~num_node_features`.\n",
      " |  \n",
      " |  num_node_features\n",
      " |      Returns the number of features per node in the graph.\n",
      " |  \n",
      " |  num_nodes\n",
      " |      Returns or sets the number of nodes in the graph.\n",
      " |      \n",
      " |      .. note::\n",
      " |          The number of nodes in your data object is typically automatically\n",
      " |          inferred, *e.g.*, when node features :obj:`x` are present.\n",
      " |          In some cases however, a graph may only be given by its edge\n",
      " |          indices :obj:`edge_index`.\n",
      " |          PyTorch Geometric then *guesses* the number of nodes\n",
      " |          according to :obj:`edge_index.max().item() + 1`, but in case there\n",
      " |          exists isolated nodes, this number has not to be correct and can\n",
      " |          therefore result in unexpected batch-wise behavior.\n",
      " |          Thus, we recommend to set the number of nodes in your data object\n",
      " |          explicitly via :obj:`data.num_nodes = ...`.\n",
      " |          You will be given a warning that requests you to do so.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2, 3],\n",
       "        [2, 3, 4, 5]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = dataset.collate(dataset[[0,1,2,3]])\n",
    "graph_ids, graph_node_counts = data.batch.unique(return_counts=True)\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "dataset.collate([Data(x=torch.randn(2,4),edge_index=torch.tensor([[0,1],[2,3]])),\n",
    "                 Data(x=torch.randn(2,4),edge_index=torch.tensor([[0,1],[2,3]]))]).edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "act = torch.nn.SiLU()\n",
    "            \n",
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, hcs_list, act = act):\n",
    "        super(MLP, self).__init__()\n",
    "        mlp = []\n",
    "        for i in range(1,len(hcs_list)):\n",
    "            mlp.append(torch.nn.Linear(hcs_list[i-1], hcs_list[i]))\n",
    "            mlp.append(torch.nn.BatchNorm1d(hcs_list[i]))\n",
    "            mlp.append(act)\n",
    "\n",
    "        self.mlp = torch.nn.Sequential(*mlp)\n",
    "    def forward(self, x):\n",
    "        return self.mlp(x)\n",
    "\n",
    "class AttGNN(torch.nn.Module):\n",
    "    def __init__(self, hcs_in, hcs_out, act = act):\n",
    "        super(AttGNN, self).__init__()\n",
    "\n",
    "        self.beta = torch.nn.Parameter(torch.ones(1)*20)\n",
    "\n",
    "        self.self_mlp = MLP([hcs_in,hcs_in,hcs_out])\n",
    "        self.msg_mlp = MLP([hcs_in,hcs_in,hcs_out])\n",
    "#     @torch.jit.script_method\n",
    "    def forward(self, x, graph_node_counts):\n",
    "        \n",
    "        li : List[int] = graph_node_counts.tolist()\n",
    "        \n",
    "        tmp = []\n",
    "        for tmp_x, msg in zip(x.split(li), self.msg_mlp(x).split(li)):\n",
    "            att = F.normalize(tmp_x,p=2.,dim=1)\n",
    "            att = torch.cdist(att,att)\n",
    "#             att = F.softmax(self.beta*att,1)\n",
    "            return att, msg\n",
    "#             att[att < att.mean()] = 0\n",
    "#             tmp.append(torch.matmul(att,msg))\n",
    "#         return self.self_mlp(x) + torch.cat(tmp,0)\n",
    "    \n",
    "#         att = []\n",
    "#         for tmp_x in x.split(li):\n",
    "#             tmp_x = F.normalize(tmp_x,p=2,dim=1)\n",
    "#             tmp_x = torch.cdist(tmp_x,tmp_x)\n",
    "#             att.append(F.softmax(self.beta*tmp_x,1))\n",
    "#         return self.self_mlp(x) + torch.matmul(torch.block_diag(*att), self.msg_mlp(x))\n",
    "        \n",
    "class Att2GNN(torch.nn.Module):\n",
    "    def __init__(self, hcs_in, hcs_out, act = act):\n",
    "        super(Att2GNN, self).__init__()\n",
    "\n",
    "        self.beta = torch.nn.Parameter(torch.ones(1)*20)\n",
    "        \n",
    "        self.att_mlp = torch.nn.Sequential(torch.nn.Linear(2*hcs_in,hcs_in),\n",
    "                                        act,\n",
    "                                        torch.nn.Linear(hcs_in,1))\n",
    "\n",
    "        self.self_mlp = MLP([hcs_in,hcs_in,hcs_out])\n",
    "        self.msg_mlp = MLP([hcs_in,hcs_in,hcs_out])\n",
    "\n",
    "    def forward(self, x, graph_node_counts):\n",
    "        \n",
    "        li : List[int] = graph_node_counts.tolist()\n",
    "        \n",
    "        tmp = []\n",
    "        for tmp_x, msg in zip(x.split(li), self.msg_mlp(x).split(li)):\n",
    "            tmp_x = torch.cat([tmp_x.unsqueeze(1) - tmp_x, tmp_x.unsqueeze(1) + tmp_x],dim=2)\n",
    "            tmp_x = self.att_mlp(tmp_x).squeeze()\n",
    "            tmp.append(torch.matmul(tmp_x,msg))\n",
    "            return tmp_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.9086],\n",
       "         [ 0.7317],\n",
       "         [ 0.4734],\n",
       "         ...,\n",
       "         [ 0.3494],\n",
       "         [-0.2203],\n",
       "         [ 0.8397]], grad_fn=<SiluBackward>),\n",
       " tensor([[ 3.8622, -0.0534,  0.0057, -0.5021, -1.4062],\n",
       "         [ 4.4093, -0.2408, -0.2593, -0.1811, -1.2178],\n",
       "         [ 5.6860, -0.1178,  0.1387,  0.1183, -1.1571],\n",
       "         ...,\n",
       "         [ 1.6737, -0.1401, -0.0323, -0.2650, -1.5259],\n",
       "         [ 2.0385, -0.3309, -0.0366,  0.0224, -1.0139],\n",
       "         [ 3.4975,  0.0430, -0.0366,  0.0224, -1.5045]]),\n",
       " tensor([[ 3.5092, -0.0485,  0.0052, -0.4562, -1.2777],\n",
       "         [ 3.2265, -0.1762, -0.1898, -0.1325, -0.8911],\n",
       "         [ 2.6917, -0.0558,  0.0656,  0.0560, -0.5478],\n",
       "         ...,\n",
       "         [ 0.5848, -0.0489, -0.0113, -0.0926, -0.5332],\n",
       "         [-0.4491,  0.0729,  0.0081, -0.0049,  0.2234],\n",
       "         [ 2.9369,  0.0361, -0.0307,  0.0188, -1.2634]], grad_fn=<MulBackward0>),\n",
       " -0.04851924)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lin = MLP([5,10,1])\n",
    "lin(x), x, lin(x)*x, 0.9086*-0.0534"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-27eb26811611>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mscripted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscript\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mAttGNN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0matt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscripted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgraph_node_counts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0matt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "scripted = torch.jit.script(AttGNN(5,64))\n",
    "att = scripted(x,graph_node_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([17,  6, 12,  6, 26,  8,  0,  8, 21, 13, 15, 21,  7,  2,  7, 13, 17, 28,\n",
       "        24, 12, 14, 31,  5, 19, 33,  2, 19,  5, 16,  9, 12, 12, 15,  3, 24])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scripted = AttGNN(5,5)\n",
    "att, msg = scripted(x,graph_node_counts)\n",
    "(att > att.mean(1)).sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.0000, 0.1455, 0.1689,  ..., 0.2689, 0.2168, 0.3944],\n",
       "         [0.1455, 0.0000, 0.1525,  ..., 0.1300, 0.1372, 0.2670],\n",
       "         [0.1689, 0.1525, 0.0000,  ..., 0.2151, 0.1194, 0.2954],\n",
       "         ...,\n",
       "         [0.2689, 0.1300, 0.2151,  ..., 0.0005, 0.1307, 0.1446],\n",
       "         [0.2168, 0.1372, 0.1194,  ..., 0.1307, 0.0000, 0.1981],\n",
       "         [0.3944, 0.2670, 0.2954,  ..., 0.1446, 0.1981, 0.0000]]),\n",
       " tensor([[-0.0576,  0.1459,  0.1877,  ...,  0.0825,  0.0890, -0.1053],\n",
       "         [-0.0747,  0.0842,  0.2075,  ...,  0.1453,  0.0875, -0.0242],\n",
       "         [-0.0798,  0.1647,  0.1707,  ...,  0.1470,  0.0782, -0.0853],\n",
       "         ...,\n",
       "         [ 0.0334,  0.0819, -0.0069,  ..., -0.0060, -0.0297,  0.0883],\n",
       "         [ 0.0591,  0.1543, -0.0432,  ..., -0.0497, -0.0600,  0.0146],\n",
       "         [ 0.1472,  0.0896, -0.1432,  ..., -0.1089, -0.1255,  0.1904]],\n",
       "        grad_fn=<SplitWithSizesBackward>))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = AttGNN(5,64)\n",
    "A(x,graph_node_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Index tensor must have the same number of dimensions as input tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-170-45e6ffd8001d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m: Index tensor must have the same number of dimensions as input tensor"
     ]
    }
   ],
   "source": [
    "torch.gather(x,-1,batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3.4501, -0.1086,  0.0457, -0.1864, -0.8372],\n",
       "        [ 3.3598, -0.1090,  0.0415, -0.1881, -0.8418],\n",
       "        [ 3.4428, -0.0911,  0.0536, -0.1820, -0.8401],\n",
       "        ...,\n",
       "        [ 3.4325, -0.1633,  0.0290, -0.1883, -1.4630],\n",
       "        [ 3.4530, -0.1633,  0.0293, -0.1890, -1.4628],\n",
       "        [ 3.5029, -0.1677,  0.0280, -0.1965, -1.4586]], dtype=torch.float64)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "def forward(x, graph_node_counts):\n",
    "    att = []\n",
    "    for tmp_x in x.split(graph_node_counts.tolist()):\n",
    "        tmp_x = F.normalize(tmp_x,p=2,dim=1)\n",
    "        tmp_x = torch.cdist(tmp_x,tmp_x)\n",
    "        att.append(F.softmax(tmp_x,1))\n",
    "    return torch.matmul(torch.block_diag(*att),x)\n",
    "graph_ids, graph_node_counts = batch.unique(return_counts=True)\n",
    "att = forward(x, graph_node_counts)\n",
    "att"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "bmm(): argument 'input' (position 1) must be Tensor, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-fc636206ecbf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph_node_counts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph_node_counts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: bmm(): argument 'input' (position 1) must be Tensor, not tuple"
     ]
    }
   ],
   "source": [
    "torch.bmm(x.split(graph_node_counts.tolist()),x.split(graph_node_counts.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function torch.nn.functional._pad(input, pad, mode='constant', value=0)>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0222, 0.0444, 0.0488,  ..., 0.0236, 0.0357, 0.0363],\n",
       "        [0.0368, 0.0184, 0.0205,  ..., 0.0357, 0.0249, 0.0246],\n",
       "        [0.0372, 0.0188, 0.0169,  ..., 0.0360, 0.0249, 0.0246],\n",
       "        ...,\n",
       "        [0.0245, 0.0447, 0.0491,  ..., 0.0230, 0.0354, 0.0360],\n",
       "        [0.0359, 0.0302, 0.0329,  ..., 0.0343, 0.0223, 0.0227],\n",
       "        [0.0361, 0.0295, 0.0321,  ..., 0.0344, 0.0224, 0.0221]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_x = dataset[0].x\n",
    "tmp_x = F.normalize(tmp_x,p=2,dim=1)\n",
    "tmp_x = torch.cdist(tmp_x,tmp_x)\n",
    "tmp_x = F.softmax(tmp_x,1)\n",
    "tmp_x\n",
    "# tmp_x = tmp_x.unsqueeze(1) - 0*tmp_x\n",
    "# tmp_x\n",
    "\n",
    "# tmp_x = F.normalize(tmp_x, p=2, dim=2)\n",
    "\n",
    "# torch.matmul(tmp_x.unsqueeze(2),tmp_x.unsqueeze(3)).squeeze()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
