

import os
from torch_geometric.data import InMemoryDataset, Data
import pandas as pd
import numpy as np
import torch_geometric.transforms as T
import torch
#In memory was just about possible with 16gb Ram and nothing else running.
#Consists of 5 input features dom_pos, dom_charge, dom_time
#Node = dom, edges is generated by k-Nearest Neighbours, with k = 6
#Runtime was a couple of hours for all 300.000 events

### TO-DO; is it CUDA optimized? If not perhaps do that.


seq = pd.read_csv('data/sequential.csv')
scalar = pd.read_csv('data/scalar.csv')

class MyOwnDataset(InMemoryDataset):
    def __init__(self, root, transform=None, pre_transform=None):
        super(MyOwnDataset, self).__init__(root, transform, pre_transform)
        self.data, self.slices = torch.load(self.processed_paths[0])

    @property
    def raw_file_names(self):
        return os.listdir('C:/Users/jv97/Desktop/github/Neutrino-Machine-Learning/raw_data')

    @property
    def processed_file_names(self):
        return os.listdir('C:/Users/jv97/Desktop/github/Neutrino-Machine-Learning/dataset/processed')

    def process(self):
        if self.processed_file_names is not None:
            return
        else:
            seq = pd.read_csv('data/sequential.csv')
            scalar = pd.read_csv('data/scalar.csv')


            data_list = []
            i = 0
            for index, sca in scalar.iterrows():
                tmp_event = seq.loc[seq['event_no'] == sca['event_no']]
                x = torch.tensor(tmp_event[['dom_charge','dom_time','dom_x','dom_y','dom_z']].to_numpy(),dtype=torch.float) #Features
                pos = torch.tensor(tmp_event[['dom_x','dom_y','dom_z']].to_numpy(),dtype=torch.float) #Position
                y = torch.tensor(sca[sca.keys()[3:]].to_numpy(),dtype=torch.float) #Target
                dat = Data(x=x,edge_index=None,edge_attr=None,y=y,pos=pos) 
                T.KNNGraph(loop=True)(dat) #defining edges by k-NN with k=6
                data_list.append(dat)
                if i % 1000 == 0:
                    print(i)
                i += 1

            if self.pre_filter is not None:
                data_list = [data for data in data_list if self.pre_filter(data)]

            if self.pre_transform is not None:
                data_list = [self.pre_transform(data) for data in data_list]

            data, slices = self.collate(data_list)

# MyOwnDataset(root = 'C:/Users/jv97/Desktop/github/Neutrino-Machine-Learning/dataset')

#Target variables are energy, time, xyz, directions xyz